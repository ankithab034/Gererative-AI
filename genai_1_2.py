# -*- coding: utf-8 -*-
"""genai_1_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u3DQ6tL55FAIlp5P3J4gBO4WibMJT32i
"""

#hugging face
from transformers import pipeline

# Load the NER pipeline with entity grouping
ner_pipeline = pipeline("ner", aggregation_strategy="simple")

# Ask user for input
user_input = input("Enter a sentence: ")

# Run NER
entities = ner_pipeline(user_input)

# Print results
print("\nNamed Entity Recognition Output:\n")
if entities:
    for ent in entities:
        print(f"âž¤ Entity: {ent['word']} | Label: {ent['entity_group']} | Score: {ent['score']:.2f}")
else:
    print("No named entities found in the sentence.")

#embeddings
spell = SpellChecker()

def tokenize(text):
    return text.lower().split()

def correct_word(word, similarity_threshold=0.5):
    # 1. If known word, keep as is
    if word in model:
        return word

    # 2. Try embedding similarity first
    try:
        sims = model.most_similar(word, topn=5)
        best_match, score = sims[0]
        if score > similarity_threshold:
            return best_match
    except:
        pass

    # 3. If embedding fails, fallback to spellchecker
    correction = spell.correction(word)
    if correction != word:
        return correction

    # 4. Lastly, try difflib close match
    alt = get_close_matches(word, model.key_to_index.keys(), n=1, cutoff=0.8)
    if alt:
        return alt[0]

    # 5. If all fails, return original word
    return word

def correct_sentence(sentence):
    words = tokenize(sentence)
    corrected = [correct_word(w) for w in words]
    return " ".join(corrected)

# User input
input_sentence = input("ðŸ“ Enter sentence with misspellings: ")
corrected_sentence = correct_sentence(input_sentence)
print("\nâœ… Corrected Sentence:", corrected_sentence)

!pip install pyspellchecker
!pip install gensim

import gensim.downloader as api
from spellchecker import SpellChecker
from difflib import get_close_matches

print("â³ Loading fastText embeddings...")
model = api.load('fasttext-wiki-news-subwords-300')
print("âœ… Embeddings loaded.")

spell = SpellChecker()

def tokenize(text):
    return text.lower().split()

def correct_word(word, similarity_threshold=0.5):
    # 1. If known word, keep as is
    if word in model:
        return word

    # 2. Try embedding similarity first
    try:
        sims = model.most_similar(word, topn=5)
        best_match, score = sims[0]
        if score > similarity_threshold:
            return best_match
    except:
        pass

    # 3. If embedding fails, fallback to spellchecker
    correction = spell.correction(word)
    if correction != word:
        return correction

    # 4. Lastly, try difflib close match
    alt = get_close_matches(word, model.key_to_index.keys(), n=1, cutoff=0.8)
    if alt:
        return alt[0]

    # 5. If all fails, return original word
    return word

def correct_sentence(sentence):
    words = tokenize(sentence)
    corrected = [correct_word(w) for w in words]
    return " ".join(corrected)

# User input
input_sentence = input(" Enter sentence with misspellings: ")
corrected_sentence = correct_sentence(input_sentence)
print("\n Corrected Sentence:", corrected_sentence)